{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a1a1c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11652/1699635188.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766a1fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed h11-0.13.0 outcome-1.2.0 selenium-4.3.0 trio-0.21.0 trio-websocket-0.9.2 wsproto-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f326055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9cebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.\n",
    "\n",
    "#You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8a909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8205bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job bar using id\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f5e578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef527b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"90986c8a39bf44b6e194d2a0ccc9cbf1\", element=\"21135ecb-5f09-4046-bf43-279dbe3178a9\")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding web element for search icon bar using relative xpath\n",
    "search_locn=driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_locn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a6a3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for job locn on bar\n",
    "search_locn.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8de8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "search_btn=driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0223f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the job title\n",
    "job_title=[]\n",
    "\n",
    "job_tag=driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "job_tag=job_tag[0:10]\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611289e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting job location\n",
    "job_location=[]\n",
    "\n",
    "job_loc=driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_loc=job_loc[0:10]\n",
    "for i in job_loc:\n",
    "    job_location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fff0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting company name\n",
    "company=[]\n",
    "\n",
    "comp=driver.find_elements(By.XPATH, \"//div[@class='mt-7 companyInfo subheading lh16']\")\n",
    "comp=comp[0:10]\n",
    "for i in comp:\n",
    "    company.append(i.text.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5a33c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experience\n",
    "exp=[]\n",
    "\n",
    "expn=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "expn=expn[0:10]\n",
    "for i in expn:\n",
    "    exp.append(i.text)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c4d6c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science / Data Engineer / Business Analys...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>NETWORTH DATA PRODUCTS PRIVATE LIMITED</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr.Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, karnataka\\n(WFH during Co...</td>\n",
       "      <td>Collabera</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hudsons bay Company (HBC)</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - IIM/ISB/MDI/FMS/SP Jain</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>K12 Techno Services Pvt Ltd</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Analyst/Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, D...</td>\n",
       "      <td>Telamon HR Solutions</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi</td>\n",
       "      <td>ICF Next</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analysis Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Capco</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Python/SQL</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Affine</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-Title  \\\n",
       "0                                     Data Analyst I   \n",
       "1  Data Science / Data Engineer / Business Analys...   \n",
       "2                           Sr.Business Data Analyst   \n",
       "3                                Senior Data Analyst   \n",
       "4                                    Sr Data Analyst   \n",
       "5             Data Analyst - IIM/ISB/MDI/FMS/SP Jain   \n",
       "6                      Business Analyst/Data Analyst   \n",
       "7                                Junior Data Analyst   \n",
       "8                       Senior Data Analysis Analyst   \n",
       "9                          Data Analyst - Python/SQL   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Bangalore/Bengaluru, karnataka\\n(WFH during Co...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Hyderabad/Secunderabad, D...   \n",
       "7                     Bangalore/Bengaluru, New Delhi   \n",
       "8                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                             Company_Name Experience_Required  \n",
       "0                                  Cerner            5-10 Yrs  \n",
       "1  NETWORTH DATA PRODUCTS PRIVATE LIMITED             0-3 Yrs  \n",
       "2                               Collabera            6-11 Yrs  \n",
       "3               Hudsons bay Company (HBC)             3-4 Yrs  \n",
       "4                         Thomson Reuters             5-8 Yrs  \n",
       "5             K12 Techno Services Pvt Ltd             4-9 Yrs  \n",
       "6                    Telamon HR Solutions             3-5 Yrs  \n",
       "7                                ICF Next             1-6 Yrs  \n",
       "8                                   Capco            7-12 Yrs  \n",
       "9                                  Affine             3-5 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creaing the data frame to get top 10 results\n",
    "\n",
    "data=pd.DataFrame({'Job-Title':job_title, 'Job-Location':job_location,'Company_Name':company,'Experience_Required':exp})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "443406a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location.\n",
    "\n",
    "#You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cde0fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "546a3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job bar using id\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01472a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8897824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search icon bar using relative xpath\n",
    "search_locn=driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_locn.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a676ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "search_btn=driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65224959",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company=[]\n",
    "\n",
    "job_tag=driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "job_tag=job_tag[0:10]\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "job_loc=driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_loc=job_loc[0:10]\n",
    "for i in job_loc:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "comp=driver.find_elements(By.XPATH, \"//div[@class='mt-7 companyInfo subheading lh16']\")\n",
    "comp=comp[0:10]\n",
    "for i in comp:\n",
    "    company.append(i.text.split('\\n')[0])\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e7504d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Spiceworks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opportunity For Data Scientist - Female Candid...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Mumbai</td>\n",
       "      <td>Paytm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-Title  \\\n",
       "0  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "1                   Hiring For Senior Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3                                 Dataiku Consultant   \n",
       "4            Research and Development -AI/ML -(PhD )   \n",
       "5  Opportunity For Data Scientist - Female Candid...   \n",
       "6                       Senior Data Science Engineer   \n",
       "7                 Data Science - Engineering Manager   \n",
       "8                                     Data Scientist   \n",
       "9  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "1                          Bangalore/Bengaluru, Pune   \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "3                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "4  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "5  Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...   \n",
       "6  Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...   \n",
       "7                 Bangalore/Bengaluru, Noida, Mumbai   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                      Company_Name  \n",
       "0                            Wipro  \n",
       "1  TATA CONSULTANCY SERVICES (TCS)  \n",
       "2                       Spiceworks  \n",
       "3                            Wipro  \n",
       "4                              EXL  \n",
       "5                             PayU  \n",
       "6                Fractal Analytics  \n",
       "7                            Paytm  \n",
       "8                Applied Materials  \n",
       "9                              PwC  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating data frame to get to 10 jobs data\n",
    "data=pd.DataFrame({'Job-Title':job_title, 'Job-Location':job_location,'Company_Name':company})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f40c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ce8a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afba7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job bar using id\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efc61883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34655a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search icon bar using relative xpath\n",
    "search_btn=driver.find_element(By.XPATH, '/html/body/div/div[2]/div[3]/div/div/div[6]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4520a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2329518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter=driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/p/span[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26f59d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d1d165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_filter=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47dd66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "008c2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company=[]\n",
    "exp=[]\n",
    "\n",
    "job_tag=driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "job_tag=job_tag[0:10]\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "job_loc=driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_loc=job_loc[0:10]\n",
    "for i in job_loc:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "comp=driver.find_elements(By.XPATH, \"//div[@class='mt-7 companyInfo subheading lh16']\")\n",
    "comp=comp[0:10]\n",
    "for i in comp:\n",
    "    company.append(i.text.split('\\n')[0])\n",
    "    \n",
    "expn=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "expn=expn[0:10]\n",
    "for i in expn:\n",
    "    exp.append(i.text)\n",
    "\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b65d1538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Associate - Data Science</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Associate</td>\n",
       "      <td>Delhi / NCR(Vaishali)</td>\n",
       "      <td>Kreate Energy</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job-Title  \\\n",
       "0             DigitalBCG GAMMA Data Scientist   \n",
       "1            Data Scientist - Noida/Bangalore   \n",
       "2             Senior Associate - Data Science   \n",
       "3  Data Scientist For Healthcare Product team   \n",
       "4  Data Scientist For Healthcare Product team   \n",
       "5              Data Scientist - MIND Infotech   \n",
       "6                      Data Science Associate   \n",
       "7           Data Scientist - Engine Algorithm   \n",
       "8                    Knowledge/Data Scientist   \n",
       "9                              Data Scientist   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0                     New Delhi, Bangalore/Bengaluru   \n",
       "1                         Noida, Bangalore/Bengaluru   \n",
       "2  Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...   \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "5                                              Noida   \n",
       "6                              Delhi / NCR(Vaishali)   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "8                                        Delhi / NCR   \n",
       "9             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                               Company_Name Experience_Required  \n",
       "0                   Boston Consulting Group             2-5 Yrs  \n",
       "1                                       EXL            5-10 Yrs  \n",
       "2                              Black Turtle             4-7 Yrs  \n",
       "3                  SECUREKLOUD TECHNOLOGIES             2-7 Yrs  \n",
       "4                  SECUREKLOUD TECHNOLOGIES             2-7 Yrs  \n",
       "5  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             4-8 Yrs  \n",
       "6                             Kreate Energy             2-4 Yrs  \n",
       "7                              Primo Hiring             1-3 Yrs  \n",
       "8                   BOLD Technology Systems             3-6 Yrs  \n",
       "9   Mount Talent Consulting Private Limited             2-4 Yrs  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating data frame to get the result\n",
    "data=pd.DataFrame({'Job-Title':job_title, 'Job-Location':job_location,'Company_Name':company,'Experience_Required':exp})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "179bc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "#Brand\n",
    "#Product Description\n",
    "#Price\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19616c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b10a4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb1e82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e012203",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element(By.CLASS_NAME, \"_3704LK\")\n",
    "search_tag.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ca3650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.CLASS_NAME, \"L0Z3Pu\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "321e4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating required list for processing\n",
    "brand=[]\n",
    "product_dis=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#Defining a function that include scrapping functions\n",
    "def scrap():\n",
    "    \n",
    "    brnd=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brnd:\n",
    "        if(len(brand)==100):\n",
    "            break\n",
    "        else:\n",
    "            brand.append(i.text)\n",
    "        dis=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "        for i in dis:\n",
    "            if(len(product_dis)==100):\n",
    "                break\n",
    "            else:\n",
    "                product_dis.append(i.text)\n",
    "        pri=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "        for j in pri:\n",
    "            if(len(price)==100):\n",
    "                break\n",
    "            else:\n",
    "                price.append(j.text)\n",
    "        dis=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "        for j in dis:\n",
    "            if(len(discount)==100):\n",
    "                break\n",
    "            else:\n",
    "                discount.append(j.text)\n",
    "                \n",
    "#now we are going to 100 sunglasses \n",
    "for i in range(0,3):\n",
    "    if(i==0):\n",
    "        scrap()\n",
    "    elif i==1:\n",
    "        driver.find_element(By.CLASS_NAME,\"_1LKTO3\").click()\n",
    "        time.sleep(3)\n",
    "        scrap()\n",
    "    elif(i==2):\n",
    "        driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]').click()\n",
    "        time.sleep(3)\n",
    "        scrap()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5ce7711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Details</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Round Sunglasses (54)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>₹177</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹249</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (60)</td>\n",
       "      <td>₹385</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹246</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹154</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Riding Glasses Wrap-around Sunglasses (Free Size)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Riding Glasses Rectangular Sung...</td>\n",
       "      <td>₹426</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                    Product Details Price  \\\n",
       "0   ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...  ₹379   \n",
       "1        ROYAL SON     UV Protection, Polarized Round Sunglasses (54)  ₹664   \n",
       "2         DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...  ₹177   \n",
       "3        New Specs   UV Protection Rectangular Sunglasses (Free Size)  ₹264   \n",
       "4           PIRASO              UV Protection Aviator Sunglasses (54)  ₹249   \n",
       "..             ...                                                ...   ...   \n",
       "95         Ray-Ban              UV Protection Cat-eye Sunglasses (60)  ₹385   \n",
       "96   VINCENT CHASE              UV Protection Aviator Sunglasses (54)  ₹246   \n",
       "97  ROZZETTA CRAFT   UV Protection Rectangular Sunglasses (Free Size)  ₹154   \n",
       "98       ROYAL SON  Riding Glasses Wrap-around Sunglasses (Free Size)  ₹299   \n",
       "99          GANSTA  UV Protection, Riding Glasses Rectangular Sung...  ₹426   \n",
       "\n",
       "   Discount  \n",
       "0   81% off  \n",
       "1   66% off  \n",
       "2   82% off  \n",
       "3   89% off  \n",
       "4   84% off  \n",
       "..      ...  \n",
       "95  73% off  \n",
       "96  84% off  \n",
       "97  89% off  \n",
       "98  88% off  \n",
       "99  80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sunglass=pd.DataFrame({'Brand':brand,'Product Details':product_dis,'Price':price,'Discount':discount})\n",
    "Sunglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e76b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "#This task will be done in following steps:\n",
    "\n",
    "#First get the webpage https://www.flipkart.com/\n",
    "#Enter “iphone 11” in “Search” field .\n",
    "#Then click the search button.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6acbdc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4bdfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "380830f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee8365ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_tag.send_keys(\"iphone 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85fd2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "295886d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now get the newly opened window\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cfdd49c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "review_sum=[]\n",
    "review_dis=[]\n",
    "\n",
    "j=1\n",
    "def i_scrap():\n",
    "    rate=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rate:\n",
    "        rating.append(i.text)\n",
    "    review=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review:\n",
    "        review_sum.append(i.text)\n",
    "    rdis=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in rdis:\n",
    "        review_dis.append(i.text)\n",
    "i_scrap()\n",
    "next_b=driver.find_elements(By.CLASS_NAME,\"ge-49M\")\n",
    "for b in next_b:\n",
    "    i_scrap()\n",
    "len(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f061da4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summery</th>\n",
       "      <th>Review_Disciption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_Summery  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5   Highly recommended   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Fabulous!   \n",
       "96      5        Great product   \n",
       "97      5    Worth every penny   \n",
       "98      4          Good choice   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                    Review_Disciption  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first iOS phone. I am very happy wi...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  So far it’s been an AMAZING experience coming ...  \n",
       "99  iphone 11 is a very good phone to buy only if ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_rating=pd.DataFrame({'Rating':rating,'Review_Summery':review_sum,'Review_Disciption':review_dis})\n",
    "iphone_rating[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7819de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2ffa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0cc1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a555558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "838f0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_tag.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db58ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ebbcf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.CLASS_NAME, \"L0Z3Pu\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "10e65c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_dis=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#Defining a function that include scrapping functions\n",
    "def scrap():\n",
    "    \n",
    "    brnd=driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brnd:\n",
    "        if(len(brand)==100):\n",
    "            break\n",
    "        else:\n",
    "            brand.append(i.text)\n",
    "        dis=driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "        for i in dis:\n",
    "            if(len(product_dis)==100):\n",
    "                break\n",
    "            else:\n",
    "                product_dis.append(i.text)\n",
    "        pri=driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "        for j in pri:\n",
    "            if(len(price)==100):\n",
    "                break\n",
    "            else:\n",
    "                price.append(j.text)\n",
    "        dis=driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]')\n",
    "        for j in dis:\n",
    "            if(len(discount)==100):\n",
    "                break\n",
    "            else:\n",
    "                discount.append(j.text)\n",
    "                \n",
    "#now we are going to 100 sunglasses \n",
    "for i in range(0,3):\n",
    "    if(i==0):\n",
    "        scrap()\n",
    "    elif i==1:\n",
    "        driver.find_element(By.CLASS_NAME,\"_1LKTO3\").click()\n",
    "        time.sleep(3)\n",
    "        scrap()\n",
    "    elif(i==2):\n",
    "        driver.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]').click()\n",
    "        time.sleep(3)\n",
    "        scrap()\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64134264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Details</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹590</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹630</td>\n",
       "      <td>36% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Puma Smash v2 L Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹397</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SiR CORBETT</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Earton</td>\n",
       "      <td>Puma Smash v2 L Sneakers For Men</td>\n",
       "      <td>₹425</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PROVOGUE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹442</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LE GREEM</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Stylish Comfortable Lightweight, Breathable Wa...</td>\n",
       "      <td>₹620</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                                    Product Details Price  \\\n",
       "0      RapidBox      Modern Trendy Sneakers Shoes Sneakers For Men  ₹590   \n",
       "1      RapidBox                                   Sneakers For Men  ₹630   \n",
       "2        BRUTON  Kwik FIT casual sneaker shoes and partywear sh...  ₹284   \n",
       "3      Magnolia                   Puma Smash v2 L Sneakers For Men  ₹399   \n",
       "4      KWIK FIT                                   Sneakers For Men  ₹397   \n",
       "..          ...                                                ...   ...   \n",
       "95  SiR CORBETT  Kwik FIT casual sneaker shoes and partywear sh...  ₹449   \n",
       "96       Earton                   Puma Smash v2 L Sneakers For Men  ₹425   \n",
       "97     PROVOGUE                                   Sneakers For Men  ₹442   \n",
       "98     LE GREEM  Original Luxury Branded Fashionable Men's Casu...  ₹299   \n",
       "99       Bonexy  Stylish Comfortable Lightweight, Breathable Wa...  ₹620   \n",
       "\n",
       "   Discount  \n",
       "0   40% off  \n",
       "1   36% off  \n",
       "2   78% off  \n",
       "3   60% off  \n",
       "4   80% off  \n",
       "..      ...  \n",
       "95  55% off  \n",
       "96  57% off  \n",
       "97  55% off  \n",
       "98  70% off  \n",
       "99  37% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating one data fram using scrapped data             \n",
    "sneakers=pd.DataFrame({'Brand':brand,'Product Details':product_dis,'Price':price,'Discount':discount})\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2a9844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7: Go to webpage https://www.amazon.in/\n",
    "\n",
    "#Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "#After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "\n",
    "#Title\n",
    "#Ratings\n",
    "#Price\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b2beb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee34e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89172937",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_searchtext=driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "amazon_searchtext.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9c64b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f30e3bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "758ce480",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_title=[]\n",
    "lap_pri=[]\n",
    "lap_rate=[]\n",
    "#def lap_scrap():\n",
    "ti=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "for i in ti:\n",
    "    if(len(lap_title)==10):\n",
    "        break\n",
    "    else:\n",
    "        lap_title.append(i.text)\n",
    "rt=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "for i in rt:\n",
    "    if(len(lap_rate)==10):\n",
    "        break\n",
    "    else:\n",
    "        lap_rate.append(i.get_attribute('aria-label'))\n",
    "\n",
    "pr=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in pr:\n",
    "    if(len(lap_pri)==10):\n",
    "        break\n",
    "    else:\n",
    "        lap_pri.append(i.text)\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2977f5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lap Titile</th>\n",
       "      <th>Lap Price</th>\n",
       "      <th>Lap Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hp 14S 11Th Gen Intel Core I3- 8Gb Ram/256Gb S...</td>\n",
       "      <td>36,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP 15- AMD Ryzen 3-3250U 15.6 inch(39.6 cm) FH...</td>\n",
       "      <td>38,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...</td>\n",
       "      <td>25,990</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell New Inspiron 3525 Laptop, AMD Athlon Silv...</td>\n",
       "      <td>31,500</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...</td>\n",
       "      <td>23,049</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP 14 10th Gen Intel Core i5 Processor 14 inch...</td>\n",
       "      <td>25,490</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 5i 11th Gen Intel Core i5 ...</td>\n",
       "      <td>69,600</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>70,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...</td>\n",
       "      <td></td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 247 G8 Laptop (Athlon P-3045B HD/ 14 inch(3...</td>\n",
       "      <td>28,980</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Lap Titile Lap Price  \\\n",
       "0  Hp 14S 11Th Gen Intel Core I3- 8Gb Ram/256Gb S...    36,990   \n",
       "1  HP 15- AMD Ryzen 3-3250U 15.6 inch(39.6 cm) FH...    38,999   \n",
       "2  ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...    25,990   \n",
       "3  Dell New Inspiron 3525 Laptop, AMD Athlon Silv...    31,500   \n",
       "4  Lenovo IdeaPad Slim 1 Intel Celeron N4020 11.6...    23,049   \n",
       "5  HP 14 10th Gen Intel Core i5 Processor 14 inch...    25,490   \n",
       "6  Lenovo IdeaPad Slim 5i 11th Gen Intel Core i5 ...    69,600   \n",
       "7                                                       70,990   \n",
       "8  Lenovo IdeaPad Slim 3 Intel Celeron N4020 15.6...             \n",
       "9  HP 247 G8 Laptop (Athlon P-3045B HD/ 14 inch(3...    28,980   \n",
       "\n",
       "           Lap Rating  \n",
       "0  4.2 out of 5 stars  \n",
       "1  4.2 out of 5 stars  \n",
       "2  4.1 out of 5 stars  \n",
       "3  4.0 out of 5 stars  \n",
       "4  3.7 out of 5 stars  \n",
       "5  4.0 out of 5 stars  \n",
       "6  4.3 out of 5 stars  \n",
       "7  4.0 out of 5 stars  \n",
       "8  4.0 out of 5 stars  \n",
       "9  3.8 out of 5 stars  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lap=pd.DataFrame({'Lap Titile':lap_title,'Lap Price':lap_pri,'Lap Rating':lap_rate})\n",
    "lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8b20ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location.\n",
    "\n",
    "#You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3995274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "134867f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"/html/body/div[1]/nav/nav/a[6]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "45095828",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input').send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30e43c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CLASS_NAME,\"ctas-btn-medium\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c56b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, \"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a085a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input').send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62733d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5449dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0e0503e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "no_day=[]\n",
    "com_rating=[]\n",
    "com=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for i in com:\n",
    "    company.append(i.text.split('\\n')[0])\n",
    "    if len(com_rating)==0:\n",
    "        com_rating.append(i.text.split('\\n')[2])\n",
    "    else:\n",
    "        com_rating.append(i.text.split('\\n')[1])\n",
    "com_rating=com_rating[:10]\n",
    "company=company[:10]\n",
    "days=driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]')\n",
    "for i in days:\n",
    "    no_day.append(i.text.split(','))\n",
    "no_day=no_day[0::2]\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f23c7c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Company Rating</th>\n",
       "      <th>No of Days ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>[11d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>[18d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latent bridge</td>\n",
       "      <td>4.5</td>\n",
       "      <td>[9d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>[16d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>InfoEdge India Ltd.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[17d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[17d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[4d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Careerera</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[12d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CRMnext</td>\n",
       "      <td>4.1</td>\n",
       "      <td>[1mon ago]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Company Company Rating  \\\n",
       "0  Optum Global Solutions (India) Private Limited            4.1   \n",
       "1  Optum Global Solutions (India) Private Limited            4.1   \n",
       "2                   GENPACT India Private Limited            4.0   \n",
       "3                                   Latent bridge            4.5   \n",
       "4                         Dew Solutions Pvt. Ltd.            4.3   \n",
       "5                             InfoEdge India Ltd.            3.9   \n",
       "6                         Info Edge India Limited            3.9   \n",
       "7                         Info Edge India Limited            3.9   \n",
       "8                                       Careerera            3.8   \n",
       "9                                         CRMnext            4.1   \n",
       "\n",
       "  No of Days ago  \n",
       "0      [11d ago]  \n",
       "1      [18d ago]  \n",
       "2       [2d ago]  \n",
       "3       [9d ago]  \n",
       "4      [16d ago]  \n",
       "5      [17d ago]  \n",
       "6      [17d ago]  \n",
       "7       [4d ago]  \n",
       "8      [12d ago]  \n",
       "9     [1mon ago]  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs=pd.DataFrame({'Company':company,'Company Rating':com_rating,'No of Days ago':no_day})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8abdce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "\n",
    "#You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "\n",
    "#connect to the web driver\n",
    "driver=webdriver.Edge(r'C:\\Users\\Nitin\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c0d520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d101f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"/html/body/div[1]/nav/nav/a[4]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c71e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input').send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "555f4c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google',\n",
       " 'Microsoft Corporation',\n",
       " 'Goldman Sachs',\n",
       " 'Tekion',\n",
       " 'Amazon',\n",
       " 'Servicenow Software Development India',\n",
       " 'Flipkart',\n",
       " 'Walmart',\n",
       " 'PayPal',\n",
       " 'Myntra']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now  we want to extract all  the  10 comapny names here \n",
    "company_names=[]\n",
    "co_nametag= driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]/a')\n",
    "\n",
    "for i in  co_nametag:\n",
    "    com_name=(i.text.split('\\n')[0])\n",
    "    company_names.append(com_name)\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "59f225ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will fetch the min, avg and max Salary\n",
    "avg_sal=[]\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "asal=driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in asal:\n",
    "    avg_sal.append(i.text)\n",
    "misal=driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for i in misal:\n",
    "    min_sal.append(i.text)\n",
    "max_sal=min_sal[1::2]\n",
    "min_sal=min_sal[0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f29d913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-3 yrs experience (based on 35 salaries)',\n",
       " '1-4 yrs experience (based on 274 salaries)',\n",
       " '2 yrs experience (based on 18 salaries)',\n",
       " '2-4 yrs experience (based on 35 salaries)',\n",
       " '1-4 yrs experience (based on 122 salaries)',\n",
       " '2-4 yrs experience (based on 60 salaries)',\n",
       " '1-4 yrs experience (based on 64 salaries)',\n",
       " '1-4 yrs experience (based on 87 salaries)',\n",
       " '1-2 yrs experience (based on 29 salaries)',\n",
       " '1 yr experience (based on 10 salaries)']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now  we  will  be fetching  the  experience   here \n",
    "company_exp=[]\n",
    "exp_tag= driver.find_elements(By.XPATH, '//div[@class=\"sbold-list-header\"]')\n",
    "for i in exp_tag:\n",
    "    com_exp=i.text\n",
    "    company_exp.append(com_exp)\n",
    "company_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0e1f7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comapnay_names</th>\n",
       "      <th>minimum_salary</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Maximum_salary</th>\n",
       "      <th>Experiences_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 31.3L</td>\n",
       "      <td>₹ 65.0L</td>\n",
       "      <td>1-3 yrs experience (based on 35 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "      <td>₹ 50.0L</td>\n",
       "      <td>1-4 yrs experience (based on 274 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "      <td>2 yrs experience (based on 18 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tekion</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 21.2L</td>\n",
       "      <td>₹ 33.0L</td>\n",
       "      <td>2-4 yrs experience (based on 35 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>1-4 yrs experience (based on 122 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Servicenow Software Development India</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 28.0L</td>\n",
       "      <td>2-4 yrs experience (based on 60 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>₹ 7.5L</td>\n",
       "      <td>₹ 20.4L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "      <td>1-4 yrs experience (based on 64 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>₹ 11.4L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 32.5L</td>\n",
       "      <td>1-4 yrs experience (based on 87 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "      <td>1-2 yrs experience (based on 29 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Myntra</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 27.0L</td>\n",
       "      <td>1 yr experience (based on 10 salaries)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Comapnay_names minimum_salary Average_salary  \\\n",
       "0                                 Google        ₹ 11.0L        ₹ 31.3L   \n",
       "1                  Microsoft Corporation        ₹ 13.0L        ₹ 24.0L   \n",
       "2                          Goldman Sachs        ₹ 12.0L        ₹ 23.0L   \n",
       "3                                 Tekion        ₹ 12.0L        ₹ 21.2L   \n",
       "4                                 Amazon         ₹ 8.0L        ₹ 21.0L   \n",
       "5  Servicenow Software Development India        ₹ 13.0L        ₹ 20.5L   \n",
       "6                               Flipkart         ₹ 7.5L        ₹ 20.4L   \n",
       "7                                Walmart        ₹ 11.4L        ₹ 20.0L   \n",
       "8                                 PayPal        ₹ 11.0L        ₹ 19.9L   \n",
       "9                                 Myntra        ₹ 14.0L        ₹ 19.5L   \n",
       "\n",
       "  Maximum_salary                             Experiences_req  \n",
       "0        ₹ 65.0L   1-3 yrs experience (based on 35 salaries)  \n",
       "1        ₹ 50.0L  1-4 yrs experience (based on 274 salaries)  \n",
       "2        ₹ 34.0L     2 yrs experience (based on 18 salaries)  \n",
       "3        ₹ 33.0L   2-4 yrs experience (based on 35 salaries)  \n",
       "4        ₹ 45.0L  1-4 yrs experience (based on 122 salaries)  \n",
       "5        ₹ 28.0L   2-4 yrs experience (based on 60 salaries)  \n",
       "6        ₹ 31.0L   1-4 yrs experience (based on 64 salaries)  \n",
       "7        ₹ 32.5L   1-4 yrs experience (based on 87 salaries)  \n",
       "8        ₹ 31.0L   1-2 yrs experience (based on 29 salaries)  \n",
       "9        ₹ 27.0L      1 yr experience (based on 10 salaries)  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = pd.DataFrame({})\n",
    "\n",
    "salary['Comapnay_names']=company_names\n",
    "salary['minimum_salary']=min_sal\n",
    "salary['Average_salary']=avg_sal\n",
    "salary['Maximum_salary']=max_sal\n",
    "salary['Experiences_req']=company_exp\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0705939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
